{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import ast\n",
    "import pickle\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "import swifter\n",
    "\n",
    "from analysis.generate_cluster_information_file import load, extract_all_information_query, to_df_query\n",
    "from baseline.image_processing import pixel_intensity_histogram\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('train_X.csv')\n",
    "train_y = pd.read_csv('train_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_num</th>\n",
       "      <th>cluster_num_intensities_avg</th>\n",
       "      <th>cluster_peak_intensities_avg</th>\n",
       "      <th>cluster_x_avg</th>\n",
       "      <th>cluster_y_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>6.680000</td>\n",
       "      <td>14.920000</td>\n",
       "      <td>513.460000</td>\n",
       "      <td>475.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.0</td>\n",
       "      <td>5.692308</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>536.201923</td>\n",
       "      <td>473.798077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.0</td>\n",
       "      <td>5.605634</td>\n",
       "      <td>11.563380</td>\n",
       "      <td>464.971831</td>\n",
       "      <td>513.746479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.0</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>22.612245</td>\n",
       "      <td>417.285714</td>\n",
       "      <td>564.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169.0</td>\n",
       "      <td>3.284024</td>\n",
       "      <td>6.621302</td>\n",
       "      <td>462.224852</td>\n",
       "      <td>509.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_num  cluster_num_intensities_avg  cluster_peak_intensities_avg  \\\n",
       "0         50.0                     6.680000                     14.920000   \n",
       "1        104.0                     5.692308                     11.375000   \n",
       "2         71.0                     5.605634                     11.563380   \n",
       "3         49.0                     8.428571                     22.612245   \n",
       "4        169.0                     3.284024                      6.621302   \n",
       "\n",
       "   cluster_x_avg  cluster_y_avg  \n",
       "0     513.460000     475.320000  \n",
       "1     536.201923     473.798077  \n",
       "2     464.971831     513.746479  \n",
       "3     417.285714     564.571429  \n",
       "4     462.224852     509.230769  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "train_y_scaled = scaler.fit_transform(train_y)\n",
    "train_X_na = train_X.fillna(0)\n",
    "train_X_na_scaled = scaler.fit_transform(train_X_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 35.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'param_distributions': {'n_estimators': [100, 500, 1000, 5000],\n",
       "  'learning_rate': [0.01, 0.05, 0.1, 0.5, 0.7],\n",
       "  'max_depth': [3, 6, 8],\n",
       "  'booster': ['gbtree', 'gblinear'],\n",
       "  'subsample': [0.5, 0.7, 1],\n",
       "  'colsample_bytree': [0.5, 0.7, 1.0],\n",
       "  'gamma': [0, 0.1, 0.5]},\n",
       " 'n_iter': 100,\n",
       " 'random_state': 1,\n",
       " 'scoring': None,\n",
       " 'estimator': XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='reg:squarederror', random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None),\n",
       " 'n_jobs': -1,\n",
       " 'iid': 'deprecated',\n",
       " 'refit': True,\n",
       " 'cv': 10,\n",
       " 'verbose': 1,\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'error_score': nan,\n",
       " 'return_train_score': False,\n",
       " 'multimetric_': False,\n",
       " 'best_index_': 60,\n",
       " 'best_score_': 0.4477113293611311,\n",
       " 'best_params_': {'subsample': 0.7,\n",
       "  'n_estimators': 1000,\n",
       "  'max_depth': 6,\n",
       "  'learning_rate': 0.01,\n",
       "  'gamma': 0.5,\n",
       "  'colsample_bytree': 1.0,\n",
       "  'booster': 'gbtree'},\n",
       " 'best_estimator_': XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1.0, gamma=0.5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=0.7, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " 'refit_time_': 10.6447434425354,\n",
       " 'scorer_': <function sklearn.metrics._scorer._passthrough_scorer(estimator, *args, **kwargs)>,\n",
       " 'cv_results_': {'mean_fit_time': array([  0.81334996,  33.21855226,   3.16645129,   0.63027451,\n",
       "           6.50144601,   6.61155937,  11.29038239,  33.04857132,\n",
       "           3.3446167 ,  22.59028821,  30.72751205,  33.3829288 ,\n",
       "           0.67084768,  33.76286945,  23.38399692,  36.06468387,\n",
       "           7.02284715,   2.14656494,  35.60195949,   0.76360126,\n",
       "           6.37208734,  74.70909498,  22.8846679 ,  10.69046302,\n",
       "           1.69514945,  25.36489556, 172.42050996,  36.61539896,\n",
       "           7.67380538,  13.33109891,  27.5447418 ,   0.79058349,\n",
       "         110.34483259,   2.19383364,  37.30623648,  14.03567576,\n",
       "           2.2283056 ,  27.44613597,   3.03734102,  73.87873113,\n",
       "          14.8812155 ,   1.73473055,  13.06970401,   1.49763966,\n",
       "         218.62832336, 167.87473443,   8.03374088,   7.33258822,\n",
       "           3.47644806,   3.52773499,   3.56314962,   3.47768817,\n",
       "           3.56637321,   3.51548357,   8.2623493 ,  35.04552038,\n",
       "           3.43567655,   3.33716989,   6.47782307,   0.76037502,\n",
       "          35.98758211,  79.27868736,   5.13588183, 118.91875026,\n",
       "          34.2083631 ,  16.28076384,   3.46474242,  26.42803135,\n",
       "           2.55323429,  70.17660084,   7.4756856 ,   0.69147992,\n",
       "           0.70884006,  64.98546431, 102.08314521,   3.19541183,\n",
       "          13.59375772,   3.42203631,  35.07583377,   3.58184421,\n",
       "           7.02634418,   0.74003811,   3.66785109,  13.3925586 ,\n",
       "           7.81385059,   2.4781853 ,   7.42677152,   7.06473553,\n",
       "           0.6923723 ,  12.95642171,  12.51229978,  34.9398222 ,\n",
       "          12.85295589,  23.25867372, 127.25695949,  36.68868334,\n",
       "           0.67074633,  34.88307941,   6.96930454,  32.68721929]),\n",
       "  'std_fit_time': array([2.76569439e-02, 3.14699521e+00, 9.34952896e-02, 2.85648935e-02,\n",
       "         1.76677621e-01, 1.11890585e-01, 7.16763879e-01, 2.24951256e-01,\n",
       "         7.41065576e-02, 1.65839229e+00, 2.55790343e+00, 4.43076925e-01,\n",
       "         2.43226032e-02, 5.43049560e-01, 1.49721378e+00, 9.82988953e-01,\n",
       "         2.49274598e-01, 1.97137874e-01, 7.82743532e-01, 1.34349524e-01,\n",
       "         4.00613495e-01, 3.91913300e+00, 1.73584129e+00, 9.67484607e-01,\n",
       "         1.95274547e-01, 2.12248866e+00, 1.55740467e+01, 1.62033718e+00,\n",
       "         7.38663543e-01, 9.66811887e-01, 3.56067277e+00, 8.98357877e-02,\n",
       "         9.33086423e+00, 2.60254001e-01, 1.38393269e+00, 1.56749406e+00,\n",
       "         3.87710283e-01, 3.41440544e+00, 4.03329951e-01, 3.71556210e+00,\n",
       "         1.21075931e+00, 3.19617472e-01, 1.26448411e+00, 1.20739777e-01,\n",
       "         1.94745691e+01, 1.38974482e+01, 5.83925812e-01, 3.27755847e-01,\n",
       "         2.60964283e-01, 2.03951938e-01, 1.20805127e-01, 2.16996833e-01,\n",
       "         2.31264250e-01, 2.06329189e-01, 6.22574071e-01, 8.35341233e-01,\n",
       "         2.04202774e-01, 3.58384214e-01, 5.13022829e-01, 6.27934936e-02,\n",
       "         3.39891897e+00, 5.15575773e+00, 7.65139073e-01, 8.29517775e+00,\n",
       "         6.04683855e-01, 1.53559643e+00, 2.13378015e-01, 2.67415096e+00,\n",
       "         2.32514826e-01, 3.52753797e+00, 6.99737135e-01, 3.66255518e-02,\n",
       "         3.55726195e-02, 2.95291470e+00, 8.15768761e+00, 2.76110356e-01,\n",
       "         7.42779486e-01, 1.11158354e-01, 2.99228872e-01, 7.97869584e-02,\n",
       "         1.29230014e-01, 4.63587207e-02, 3.96286847e-01, 6.60207525e-01,\n",
       "         4.48622975e-01, 1.93128407e-01, 2.12370057e-01, 1.22796333e-01,\n",
       "         2.59883884e-02, 5.58458281e-01, 7.85836482e-01, 4.42897384e-01,\n",
       "         9.85430408e-01, 1.51664238e+00, 1.20124256e+01, 3.95273032e+00,\n",
       "         1.67954571e-02, 4.38290280e-01, 1.40378435e-01, 6.83746392e-01]),\n",
       "  'mean_score_time': array([0.00505943, 0.05778458, 0.00520813, 0.00456312, 0.00540648,\n",
       "         0.00461299, 0.09696944, 0.00496008, 0.00466268, 0.11150234,\n",
       "         0.0681514 , 0.00515871, 0.00471208, 0.00763857, 0.20425534,\n",
       "         0.00575395, 0.00550592, 0.01845095, 0.00476165, 0.00818396,\n",
       "         0.02733009, 0.53563662, 0.09984615, 0.05714004, 0.00848176,\n",
       "         0.14027023, 2.790977  , 0.00496027, 0.00565467, 0.0941422 ,\n",
       "         0.10083816, 0.00605152, 1.15311477, 0.01631873, 0.00580323,\n",
       "         0.07023454, 0.01076348, 0.08461847, 0.02698295, 0.28217783,\n",
       "         0.0681021 , 0.00972168, 0.07613695, 0.00892806, 0.72679594,\n",
       "         1.61419837, 0.02817328, 0.00798576, 0.00500965, 0.00788643,\n",
       "         0.00471244, 0.0047617 , 0.00510914, 0.00466273, 0.03025656,\n",
       "         0.00540648, 0.00461287, 0.01919551, 0.0305541 , 0.00734096,\n",
       "         0.13183808, 0.22354958, 0.02351091, 0.17747049, 0.00679522,\n",
       "         0.10411167, 0.00753944, 0.12420003, 0.01974151, 0.26313081,\n",
       "         0.00838294, 0.00491066, 0.0047122 , 0.2678427 , 1.25499082,\n",
       "         0.018997  , 0.058131  , 0.00620008, 0.00570416, 0.00476177,\n",
       "         0.00491042, 0.00476196, 0.01785641, 0.05570142, 0.02812383,\n",
       "         0.01691399, 0.00505719, 0.00555522, 0.00570407, 0.05738795,\n",
       "         0.09374483, 0.00510883, 0.06413469, 0.11566861, 0.15291848,\n",
       "         0.02331245, 0.00476179, 0.00520799, 0.00481167, 0.00386858]),\n",
       "  'std_score_time': array([4.86290469e-04, 5.89077381e-03, 1.31698081e-03, 2.97777121e-04,\n",
       "         2.51406220e-03, 2.27416435e-04, 2.32154291e-02, 9.14789044e-04,\n",
       "         2.42858811e-04, 1.20659813e-02, 8.77598213e-03, 8.64707307e-04,\n",
       "         3.99594410e-04, 8.70564169e-03, 5.30634344e-02, 2.08349576e-03,\n",
       "         9.26775880e-04, 1.08708833e-02, 3.96675008e-04, 8.77235012e-03,\n",
       "         1.28290784e-03, 2.03991651e-01, 1.86705706e-02, 1.40937347e-02,\n",
       "         1.75304532e-03, 2.85528769e-02, 4.57390220e-01, 4.43903080e-04,\n",
       "         1.38901306e-03, 1.87300561e-02, 2.38310995e-02, 2.05477616e-03,\n",
       "         1.91569723e-01, 2.96328247e-03, 1.66064936e-03, 1.45410510e-02,\n",
       "         8.22553604e-03, 2.42408833e-02, 1.81840753e-02, 7.20330827e-02,\n",
       "         1.81324986e-02, 2.56991640e-03, 2.40666188e-02, 1.71820836e-03,\n",
       "         9.10532591e-02, 1.84420190e-01, 2.37676037e-03, 6.10922714e-03,\n",
       "         8.99658215e-04, 8.66088760e-03, 3.32667387e-04, 3.96847750e-04,\n",
       "         1.11041488e-03, 4.54624214e-04, 4.82433789e-03, 1.20382057e-03,\n",
       "         4.46415088e-04, 2.54905298e-03, 5.37516243e-03, 6.51564463e-03,\n",
       "         1.70035041e-02, 3.09485367e-02, 1.08538640e-02, 1.99378384e-02,\n",
       "         3.69192714e-03, 2.09613085e-02, 7.05963368e-03, 1.70916868e-02,\n",
       "         8.67582684e-03, 2.44762401e-02, 6.56744624e-03, 5.17878564e-04,\n",
       "         6.74494033e-04, 1.72419698e-02, 1.17631359e-01, 2.19656365e-03,\n",
       "         4.28829312e-03, 2.48257940e-03, 2.26498120e-03, 4.54749689e-04,\n",
       "         9.26588211e-04, 5.05881432e-04, 6.39832672e-03, 4.12063732e-03,\n",
       "         2.90128810e-03, 5.70502798e-03, 6.58404104e-04, 2.78648180e-03,\n",
       "         3.40201034e-03, 3.42252809e-03, 1.36488454e-02, 1.13209385e-03,\n",
       "         3.28889034e-03, 7.04860787e-03, 1.84819472e-02, 3.03358704e-03,\n",
       "         1.11360979e-03, 6.74625434e-04, 5.45606009e-04, 1.05925465e-03]),\n",
       "  'param_subsample': masked_array(data=[0.7, 0.7, 0.7, 1, 0.5, 0.5, 0.5, 0.7, 1, 0.5, 0.7, 0.5,\n",
       "                     1, 1, 0.5, 1, 0.7, 0.7, 0.5, 1, 0.5, 0.5, 0.5, 1, 1,\n",
       "                     0.5, 0.7, 0.7, 1, 0.5, 1, 1, 1, 0.7, 0.5, 0.7, 0.5, 1,\n",
       "                     1, 0.7, 0.7, 0.7, 0.5, 0.5, 0.5, 0.5, 0.7, 0.5, 0.5,\n",
       "                     0.5, 0.7, 0.7, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.5, 0.7,\n",
       "                     0.7, 0.7, 1, 0.5, 1, 0.7, 0.7, 0.7, 1, 0.7, 1, 1, 1,\n",
       "                     0.5, 1, 0.7, 0.7, 0.5, 1, 0.7, 0.5, 1, 0.7, 0.7, 0.7,\n",
       "                     0.5, 0.5, 1, 0.7, 0.5, 0.7, 1, 0.7, 0.5, 1, 1, 1, 1,\n",
       "                     0.7, 1],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_n_estimators': masked_array(data=[100, 1000, 500, 100, 1000, 1000, 500, 5000, 500, 1000,\n",
       "                     1000, 5000, 100, 5000, 1000, 5000, 1000, 100, 5000,\n",
       "                     100, 500, 5000, 500, 500, 100, 1000, 5000, 5000, 1000,\n",
       "                     500, 500, 100, 5000, 100, 5000, 500, 100, 1000, 100,\n",
       "                     5000, 1000, 100, 500, 100, 5000, 5000, 500, 1000, 500,\n",
       "                     500, 500, 500, 500, 500, 500, 5000, 500, 100, 500, 100,\n",
       "                     1000, 5000, 100, 5000, 5000, 500, 500, 500, 100, 5000,\n",
       "                     1000, 100, 100, 5000, 5000, 100, 1000, 500, 5000, 500,\n",
       "                     1000, 100, 100, 1000, 500, 100, 1000, 1000, 100, 1000,\n",
       "                     500, 5000, 500, 1000, 5000, 1000, 100, 5000, 1000,\n",
       "                     5000],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_max_depth': masked_array(data=[3, 6, 6, 6, 6, 6, 8, 3, 3, 6, 8, 6, 8, 6, 8, 3, 6, 6,\n",
       "                     3, 8, 3, 8, 8, 6, 3, 6, 8, 6, 3, 8, 8, 3, 6, 6, 6, 6,\n",
       "                     3, 8, 8, 3, 3, 3, 6, 3, 8, 6, 3, 3, 8, 8, 3, 6, 8, 3,\n",
       "                     3, 8, 6, 8, 3, 6, 6, 3, 8, 6, 3, 8, 6, 8, 6, 3, 3, 3,\n",
       "                     6, 3, 6, 8, 3, 8, 8, 8, 3, 6, 6, 3, 3, 6, 6, 3, 8, 3,\n",
       "                     8, 3, 6, 8, 6, 6, 6, 8, 8, 3],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_learning_rate': masked_array(data=[0.01, 0.7, 0.1, 0.01, 0.1, 0.1, 0.7, 0.05, 0.05, 0.5,\n",
       "                     0.7, 0.7, 0.05, 0.01, 0.1, 0.5, 0.01, 0.7, 0.7, 0.1,\n",
       "                     0.1, 0.5, 0.1, 0.7, 0.01, 0.01, 0.05, 0.1, 0.01, 0.1,\n",
       "                     0.5, 0.1, 0.01, 0.01, 0.7, 0.1, 0.01, 0.1, 0.1, 0.1,\n",
       "                     0.01, 0.1, 0.1, 0.05, 0.05, 0.1, 0.01, 0.5, 0.05, 0.01,\n",
       "                     0.1, 0.7, 0.5, 0.5, 0.01, 0.1, 0.7, 0.7, 0.1, 0.05,\n",
       "                     0.01, 0.7, 0.05, 0.7, 0.05, 0.05, 0.01, 0.5, 0.05, 0.1,\n",
       "                     0.7, 0.7, 0.5, 0.05, 0.01, 0.01, 0.01, 0.01, 0.5, 0.01,\n",
       "                     0.5, 0.5, 0.5, 0.7, 0.1, 0.5, 0.7, 0.5, 0.05, 0.01,\n",
       "                     0.5, 0.5, 0.05, 0.5, 0.05, 0.7, 0.7, 0.7, 0.1, 0.05],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_gamma': masked_array(data=[0, 0.5, 0, 0.1, 0.1, 0, 0, 0.1, 0.5, 0.1, 0.1, 0.1,\n",
       "                     0.1, 0.1, 0.1, 0.1, 0.1, 0.5, 0.1, 0.5, 0.1, 0, 0, 0,\n",
       "                     0.5, 0, 0, 0.5, 0.1, 0, 0, 0, 0.5, 0, 0.5, 0.5, 0, 0.5,\n",
       "                     0, 0.1, 0, 0, 0.5, 0, 0.5, 0, 0, 0, 0, 0, 0.1, 0, 0.5,\n",
       "                     0.1, 0.1, 0.5, 0.1, 0, 0, 0, 0.5, 0.1, 0, 0.5, 0, 0.1,\n",
       "                     0.1, 0, 0.1, 0.5, 0.5, 0, 0.5, 0, 0.1, 0.5, 0.1, 0.1,\n",
       "                     0.5, 0.1, 0.5, 0, 0, 0.1, 0.1, 0.5, 0, 0, 0, 0.5, 0,\n",
       "                     0.1, 0, 0.1, 0.5, 0.5, 0, 0.5, 0.1, 0.1],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_colsample_bytree': masked_array(data=[0.7, 1.0, 0.7, 0.7, 0.7, 0.7, 0.5, 1.0, 1.0, 0.7, 0.7,\n",
       "                     0.7, 0.5, 1.0, 0.5, 0.7, 0.7, 0.5, 0.5, 1.0, 0.5, 0.7,\n",
       "                     1.0, 0.5, 0.7, 0.7, 0.7, 1.0, 0.7, 0.5, 1.0, 1.0, 0.5,\n",
       "                     0.5, 1.0, 0.7, 1.0, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7,\n",
       "                     1.0, 1.0, 0.7, 0.7, 0.7, 0.5, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                     1.0, 0.5, 0.7, 0.5, 0.5, 1.0, 0.7, 1.0, 0.7, 0.7, 0.7,\n",
       "                     0.7, 1.0, 0.5, 0.5, 1.0, 0.7, 0.7, 0.5, 0.5, 0.7, 0.5,\n",
       "                     1.0, 0.5, 1.0, 1.0, 0.7, 1.0, 0.5, 0.7, 0.7, 0.7, 1.0,\n",
       "                     0.5, 0.5, 0.5, 0.5, 0.7, 0.5, 0.7, 1.0, 1.0, 0.7, 0.7,\n",
       "                     0.5],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_booster': masked_array(data=['gblinear', 'gbtree', 'gblinear', 'gblinear',\n",
       "                     'gblinear', 'gblinear', 'gbtree', 'gblinear',\n",
       "                     'gblinear', 'gbtree', 'gbtree', 'gblinear', 'gblinear',\n",
       "                     'gblinear', 'gbtree', 'gblinear', 'gblinear', 'gbtree',\n",
       "                     'gblinear', 'gblinear', 'gbtree', 'gbtree', 'gbtree',\n",
       "                     'gbtree', 'gbtree', 'gbtree', 'gbtree', 'gblinear',\n",
       "                     'gblinear', 'gbtree', 'gbtree', 'gblinear', 'gbtree',\n",
       "                     'gbtree', 'gblinear', 'gbtree', 'gbtree', 'gbtree',\n",
       "                     'gbtree', 'gbtree', 'gbtree', 'gbtree', 'gbtree',\n",
       "                     'gbtree', 'gbtree', 'gbtree', 'gbtree', 'gblinear',\n",
       "                     'gblinear', 'gblinear', 'gblinear', 'gblinear',\n",
       "                     'gblinear', 'gblinear', 'gbtree', 'gblinear',\n",
       "                     'gblinear', 'gbtree', 'gbtree', 'gblinear', 'gbtree',\n",
       "                     'gbtree', 'gbtree', 'gbtree', 'gblinear', 'gbtree',\n",
       "                     'gblinear', 'gbtree', 'gbtree', 'gbtree', 'gblinear',\n",
       "                     'gblinear', 'gblinear', 'gbtree', 'gbtree', 'gbtree',\n",
       "                     'gbtree', 'gblinear', 'gblinear', 'gblinear',\n",
       "                     'gblinear', 'gblinear', 'gbtree', 'gbtree', 'gbtree',\n",
       "                     'gbtree', 'gblinear', 'gblinear', 'gblinear', 'gbtree',\n",
       "                     'gbtree', 'gblinear', 'gbtree', 'gbtree', 'gbtree',\n",
       "                     'gbtree', 'gblinear', 'gblinear', 'gblinear',\n",
       "                     'gblinear'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'subsample': 0.7,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.01,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 500,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 0.5,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.5,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gbtree'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 100,\n",
       "    'max_depth': 6,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0,\n",
       "    'colsample_bytree': 1.0,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.7,\n",
       "    'gamma': 0.5,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 0.7,\n",
       "    'n_estimators': 1000,\n",
       "    'max_depth': 8,\n",
       "    'learning_rate': 0.1,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.7,\n",
       "    'booster': 'gblinear'},\n",
       "   {'subsample': 1,\n",
       "    'n_estimators': 5000,\n",
       "    'max_depth': 3,\n",
       "    'learning_rate': 0.05,\n",
       "    'gamma': 0.1,\n",
       "    'colsample_bytree': 0.5,\n",
       "    'booster': 'gblinear'}],\n",
       "  'split0_test_score': array([ 0.12593855,  0.08785115,  0.33346066,  0.12593855,  0.33346066,\n",
       "          0.33346066, -0.15946263,  0.33346063,  0.33346063,  0.10559761,\n",
       "          0.08113338,  0.33346068,  0.33273614,  0.3334603 ,  0.36897192,\n",
       "          0.3334607 ,  0.33344395,  0.17815068,  0.33346068,  0.33344885,\n",
       "          0.4292683 ,  0.00140349,  0.36373436,  0.24255527,  0.15495324,\n",
       "          0.45800006,  0.39327142,  0.33346066,  0.33344395,  0.37279109,\n",
       "          0.28387999,  0.33344885,  0.43412687,  0.13975026,  0.33346068,\n",
       "          0.39992741,  0.17938359,  0.39239588,  0.42648605,  0.34534596,\n",
       "          0.43016878,  0.43418185,  0.38595341,  0.42976965,  0.38006497,\n",
       "          0.3251629 ,  0.43272111,  0.3334607 ,  0.33346063,  0.33265677,\n",
       "          0.33346066,  0.33346068,  0.3334607 ,  0.3334607 ,  0.43273017,\n",
       "          0.33346066,  0.33346068,  0.10055476,  0.43055669,  0.33273614,\n",
       "          0.46266695,  0.07944317,  0.4621019 , -0.03442709,  0.33346063,\n",
       "          0.42566716,  0.33265677,  0.22007435,  0.43103442,  0.34807708,\n",
       "          0.33346068,  0.33346068,  0.3334607 ,  0.39384923,  0.41707026,\n",
       "          0.18953554,  0.43017877,  0.33265677,  0.3334607 ,  0.33265677,\n",
       "          0.3334607 ,  0.3334607 ,  0.29087724,  0.1460972 ,  0.43044058,\n",
       "          0.21290379,  0.33346068,  0.3334607 ,  0.33273614,  0.4306183 ,\n",
       "          0.19625284,  0.3334607 ,  0.44211506,  0.06787311,  0.4472776 ,\n",
       "          0.27167806,  0.33346068,  0.33346068,  0.33346066,  0.33346063]),\n",
       "  'split1_test_score': array([ 0.14188863,  0.09670411,  0.31811155,  0.14188863,  0.31811155,\n",
       "          0.31811155, -0.20572671,  0.31811157,  0.31811157,  0.08510324,\n",
       "          0.09447814,  0.31811152,  0.31863301,  0.31811174,  0.34492478,\n",
       "          0.31811152,  0.3181405 ,  0.22256435,  0.31811152,  0.31813234,\n",
       "          0.42631184,  0.06097604,  0.36560828,  0.21388818,  0.16299147,\n",
       "          0.4420648 ,  0.37762953,  0.31811155,  0.3181405 ,  0.36028194,\n",
       "          0.27400664,  0.31813234,  0.41610318,  0.1534136 ,  0.31811152,\n",
       "          0.39399307,  0.18678996,  0.37631018,  0.39903363,  0.34621781,\n",
       "          0.40840667,  0.41569944,  0.38479936,  0.41149909,  0.38935074,\n",
       "          0.35293063,  0.41043051,  0.31811152,  0.31811157,  0.31866831,\n",
       "          0.31811155,  0.31811152,  0.31811152,  0.31811152,  0.41043039,\n",
       "          0.31811155,  0.31811152,  0.04542668,  0.4224207 ,  0.31863301,\n",
       "          0.44427276,  0.07964866,  0.43572074, -0.19052855,  0.31811157,\n",
       "          0.42253024,  0.31866831,  0.22515283,  0.41119427,  0.35793178,\n",
       "          0.31811152,  0.31811152,  0.31811152,  0.38771071,  0.40610693,\n",
       "          0.20099164,  0.40838569,  0.31866831,  0.31811152,  0.31866831,\n",
       "          0.31811152,  0.31811152,  0.26242997,  0.17363618,  0.41645338,\n",
       "          0.24139286,  0.31811152,  0.31811152,  0.31863301,  0.41016632,\n",
       "          0.2361962 ,  0.31811152,  0.42593608,  0.09937035,  0.41837021,\n",
       "          0.28395596,  0.31811152,  0.31811152,  0.31811155,  0.31811157]),\n",
       "  'split2_test_score': array([ 0.10232706,  0.07053845,  0.29423075,  0.10232706,  0.29423075,\n",
       "          0.29423075, -0.18196353,  0.29423075,  0.29423075,  0.01621745,\n",
       "          0.05213742,  0.29423076,  0.29455453,  0.29423073,  0.36854969,\n",
       "          0.29423076,  0.29426667,  0.20442184,  0.29423076,  0.29425676,\n",
       "          0.41624971,  0.02136606,  0.36590637,  0.19895018,  0.13662047,\n",
       "          0.43536696,  0.37973152,  0.29423075,  0.29426667,  0.37811384,\n",
       "          0.30176594,  0.29425676,  0.4088717 ,  0.12737469,  0.29423076,\n",
       "          0.3888616 ,  0.16088062,  0.39142963,  0.41037695,  0.31900608,\n",
       "          0.40850633,  0.41780505,  0.37532568,  0.41010899,  0.35893524,\n",
       "          0.30928673,  0.4110865 ,  0.29423076,  0.29423075,  0.29456415,\n",
       "          0.29423075,  0.29423076,  0.29423076,  0.29423076,  0.41108109,\n",
       "          0.29423075,  0.29423076,  0.06626584,  0.41369253,  0.29455453,\n",
       "          0.44095311,  0.08303087,  0.44002645, -0.2330968 ,  0.29423075,\n",
       "          0.40964712,  0.29456415,  0.18283532,  0.40646271,  0.32804607,\n",
       "          0.29423076,  0.29423076,  0.29423076,  0.37530584,  0.40466929,\n",
       "          0.18147606,  0.40851007,  0.29456415,  0.29423076,  0.29456415,\n",
       "          0.29423076,  0.29423076,  0.25219653,  0.16609825,  0.41999102,\n",
       "          0.22133172,  0.29423076,  0.29423076,  0.29455453,  0.40886711,\n",
       "          0.18495052,  0.29423076,  0.4220405 ,  0.11394032,  0.40823886,\n",
       "          0.2616816 ,  0.29423076,  0.29423076,  0.29423075,  0.29423075]),\n",
       "  'split3_test_score': array([ 0.13821659,  0.15051858,  0.31478814,  0.13821659,  0.31478814,\n",
       "          0.31478814, -0.12372434,  0.31478812,  0.31478812,  0.09828814,\n",
       "          0.05610812,  0.31478815,  0.31416983,  0.31478798,  0.33971047,\n",
       "          0.31478815,  0.31475916,  0.17134969,  0.31478815,  0.31476741,\n",
       "          0.42413916,  0.0639781 ,  0.34986455,  0.15490682,  0.16784224,\n",
       "          0.44883471,  0.36376622,  0.31478814,  0.31475916,  0.3351834 ,\n",
       "          0.2998508 ,  0.31476741,  0.42734372,  0.15466394,  0.31478815,\n",
       "          0.39671615,  0.19816616,  0.39763974,  0.41157258,  0.34259093,\n",
       "          0.41961678,  0.43414836,  0.38983787,  0.41900694,  0.38997938,\n",
       "          0.3295661 ,  0.42329746,  0.31478815,  0.31478812,  0.3141065 ,\n",
       "          0.31478814,  0.31478815,  0.31478815,  0.31478815,  0.42329767,\n",
       "          0.31478814,  0.31478815,  0.11200284,  0.41966231,  0.31416983,\n",
       "          0.46146194,  0.11759381,  0.47003187, -0.09505273,  0.31478812,\n",
       "          0.42676502,  0.3141065 ,  0.19974404,  0.41460267,  0.35025576,\n",
       "          0.31478815,  0.31478815,  0.31478815,  0.3834844 ,  0.41114593,\n",
       "          0.20922395,  0.41952394,  0.3141065 ,  0.31478815,  0.3141065 ,\n",
       "          0.31478815,  0.31478815,  0.31345607,  0.15441314,  0.43590534,\n",
       "          0.24293715,  0.31478815,  0.31478815,  0.31416983,  0.42123302,\n",
       "          0.18936971,  0.31478815,  0.43673906,  0.12356554,  0.4362207 ,\n",
       "          0.3129082 ,  0.31478815,  0.31478815,  0.31478814,  0.31478812]),\n",
       "  'split4_test_score': array([ 0.17217816,  0.1746307 ,  0.3339045 ,  0.17217816,  0.3339045 ,\n",
       "          0.3339045 , -0.08714133,  0.33390453,  0.33390453,  0.03165086,\n",
       "          0.12489388,  0.33390445,  0.33424168,  0.33390483,  0.37744262,\n",
       "          0.33390446,  0.33390778,  0.21913219,  0.33390445,  0.3339066 ,\n",
       "          0.44246154,  0.14401504,  0.40865143,  0.21701155,  0.20187489,\n",
       "          0.4710198 ,  0.4158873 ,  0.3339045 ,  0.33390778,  0.39731101,\n",
       "          0.32638522,  0.3339066 ,  0.45749208,  0.19135678,  0.33390445,\n",
       "          0.44115161,  0.22747174,  0.43453792,  0.44360794,  0.38164374,\n",
       "          0.43201851,  0.44570066,  0.42344171,  0.43632389,  0.40124283,\n",
       "          0.34091574,  0.43353722,  0.33390446,  0.33390453,  0.33426933,\n",
       "          0.3339045 ,  0.33390445,  0.33390446,  0.33390446,  0.4335455 ,\n",
       "          0.3339045 ,  0.33390445,  0.03675261,  0.44379496,  0.33424168,\n",
       "          0.48371254,  0.15511233,  0.48238294, -0.14048043,  0.33390453,\n",
       "          0.45963879,  0.33426933,  0.2059569 ,  0.44425904,  0.38019686,\n",
       "          0.33390445,  0.33390445,  0.33390446,  0.41112494,  0.44830195,\n",
       "          0.24201414,  0.4321058 ,  0.33426933,  0.33390446,  0.33426933,\n",
       "          0.33390446,  0.33390446,  0.29279337,  0.1535894 ,  0.4478609 ,\n",
       "          0.22392603,  0.33390445,  0.33390446,  0.33424168,  0.43342353,\n",
       "          0.22639234,  0.33390446,  0.45527735,  0.06503703,  0.47660963,\n",
       "          0.32651298,  0.33390445,  0.33390445,  0.3339045 ,  0.33390453]),\n",
       "  'split5_test_score': array([ 0.13000718, -0.02676575,  0.32459662,  0.13000718,  0.32459662,\n",
       "          0.32459662, -0.26472643,  0.32459661,  0.32459661, -0.0489085 ,\n",
       "         -0.0037539 ,  0.32459661,  0.32434403,  0.3245966 ,  0.27945931,\n",
       "          0.32459661,  0.32458567,  0.14975765,  0.32459661,  0.32458869,\n",
       "          0.41486609,  0.05321818,  0.3205081 ,  0.14517537,  0.16416158,\n",
       "          0.4367104 ,  0.33958865,  0.32459662,  0.32458567,  0.31373167,\n",
       "          0.25860574,  0.32458869,  0.40617868,  0.15108706,  0.32459661,\n",
       "          0.3567193 ,  0.18762776,  0.38870754,  0.41171081,  0.29368534,\n",
       "          0.4196672 ,  0.42359913,  0.33984062,  0.41802921,  0.32942302,\n",
       "          0.2578308 ,  0.42011123,  0.32459661,  0.32459661,  0.32431373,\n",
       "          0.32459662,  0.32459661,  0.32459661,  0.32459661,  0.42010944,\n",
       "          0.32459662,  0.32459661,  0.01343733,  0.41582978,  0.32434403,\n",
       "          0.44689788,  0.03178662,  0.4390775 , -0.1956678 ,  0.32459661,\n",
       "          0.39634864,  0.32431373,  0.1479591 ,  0.41736484,  0.29885466,\n",
       "          0.32459661,  0.32459661,  0.32459661,  0.35393643,  0.40199451,\n",
       "          0.20219119,  0.41980694,  0.32431373,  0.32459661,  0.32431373,\n",
       "          0.32459661,  0.32459661,  0.25711685,  0.08647659,  0.42274122,\n",
       "          0.15449799,  0.32459661,  0.32459661,  0.32434403,  0.41904137,\n",
       "          0.12687988,  0.32459661,  0.40938347, -0.00739458,  0.41970908,\n",
       "          0.2631199 ,  0.32459661,  0.32459661,  0.32459662,  0.32459661]),\n",
       "  'split6_test_score': array([ 0.15628455,  0.10259371,  0.28659112,  0.15628455,  0.28659112,\n",
       "          0.28659112, -0.21388604,  0.28659121,  0.28659121,  0.01207107,\n",
       "          0.00798865,  0.28659106,  0.28766048,  0.28659191,  0.34519016,\n",
       "          0.28659106,  0.28660821,  0.19022163,  0.28659106,  0.28660288,\n",
       "          0.42285431,  0.09099238,  0.35030312,  0.16873637,  0.19288114,\n",
       "          0.43836713,  0.37494273,  0.28659112,  0.28660821,  0.35595441,\n",
       "          0.2824016 ,  0.28660288,  0.40827322,  0.18836757,  0.28659106,\n",
       "          0.38551375,  0.21660872,  0.39694281,  0.40663447,  0.35629945,\n",
       "          0.40390267,  0.41584779,  0.38493956,  0.40584   ,  0.35881439,\n",
       "          0.30175954,  0.40529692,  0.28659106,  0.28659121,  0.28776228,\n",
       "          0.28659112,  0.28659106,  0.28659106,  0.28659106,  0.40528797,\n",
       "          0.28659112,  0.28659106,  0.08695693,  0.41821796,  0.28766048,\n",
       "          0.43295481,  0.05210573,  0.43202771, -0.16587726,  0.28659121,\n",
       "          0.40620473,  0.28776228,  0.14761127,  0.40918078,  0.36427881,\n",
       "          0.28659106,  0.28659106,  0.28659106,  0.38405628,  0.40634853,\n",
       "          0.2397137 ,  0.40407158,  0.28776228,  0.28659106,  0.28776228,\n",
       "          0.28659106,  0.28659106,  0.2567765 ,  0.14355695,  0.42344724,\n",
       "          0.17776697,  0.28659106,  0.28659106,  0.28766048,  0.40489228,\n",
       "          0.15779025,  0.28659106,  0.42297047,  0.0039011 ,  0.41620339,\n",
       "          0.28482353,  0.28659106,  0.28659106,  0.28659112,  0.28659121]),\n",
       "  'split7_test_score': array([ 0.1292741 ,  0.04506701,  0.31029388,  0.1292741 ,  0.31029388,\n",
       "          0.31029388, -0.16737977,  0.3102939 ,  0.3102939 ,  0.09289794,\n",
       "          0.09309651,  0.31029388,  0.31044169,  0.31029402,  0.29578811,\n",
       "          0.31029388,  0.31029871,  0.15891679,  0.31029388,  0.31029728,\n",
       "          0.39516696,  0.02649652,  0.32551229,  0.18500383,  0.15504036,\n",
       "          0.41917622,  0.34339496,  0.31029388,  0.31029871,  0.31845791,\n",
       "          0.23753568,  0.31029728,  0.39558669,  0.13928244,  0.31029388,\n",
       "          0.37204098,  0.17902516,  0.3650762 ,  0.3873716 ,  0.30124896,\n",
       "          0.39147001,  0.39840304,  0.34813483,  0.39325607,  0.33854618,\n",
       "          0.28844574,  0.39780682,  0.31029388,  0.3102939 ,  0.31044685,\n",
       "          0.31029388,  0.31029388,  0.31029388,  0.31029388,  0.39796055,\n",
       "          0.31029388,  0.31029388,  0.11553817,  0.39652787,  0.31044169,\n",
       "          0.42505721, -0.00569798,  0.42502846, -0.20771762,  0.3102939 ,\n",
       "          0.39807285,  0.31044685,  0.13889955,  0.39530196,  0.30379101,\n",
       "          0.31029388,  0.31029388,  0.31029388,  0.34274244,  0.38371736,\n",
       "          0.19004411,  0.39108766,  0.31044685,  0.31029388,  0.31044685,\n",
       "          0.31029388,  0.31029388,  0.25090451,  0.05192593,  0.40407846,\n",
       "          0.10757733,  0.31029388,  0.31029388,  0.31044169,  0.39419086,\n",
       "          0.1557012 ,  0.31029388,  0.40672487, -0.07642706,  0.38688949,\n",
       "          0.26422905,  0.31029388,  0.31029388,  0.31029388,  0.3102939 ]),\n",
       "  'split8_test_score': array([ 0.11508987,  0.05849277,  0.30882008,  0.11508987,  0.30882008,\n",
       "          0.30882008, -0.16124887,  0.30882006,  0.30882006,  0.0431438 ,\n",
       "          0.03475263,  0.3088201 ,  0.30847792,  0.3088199 ,  0.31064384,\n",
       "          0.3088201 ,  0.30881859,  0.12517113,  0.3088201 ,  0.30881932,\n",
       "          0.40108303,  0.04178653,  0.33956442,  0.16156668,  0.14014103,\n",
       "          0.42223798,  0.35834336,  0.30882008,  0.30881859,  0.33071562,\n",
       "          0.26942111,  0.30881932,  0.38870884,  0.12686184,  0.3088201 ,\n",
       "          0.38455993,  0.16589575,  0.35583096,  0.3803094 ,  0.29962041,\n",
       "          0.39741109,  0.40886867,  0.36299964,  0.3995739 ,  0.35958883,\n",
       "          0.32746246,  0.40103186,  0.3088201 ,  0.30882006,  0.30843104,\n",
       "          0.30882008,  0.3088201 ,  0.3088201 ,  0.3088201 ,  0.40104744,\n",
       "          0.30882008,  0.3088201 ,  0.02940716,  0.39323481,  0.30847792,\n",
       "          0.43549859,  0.07578979,  0.43300491, -0.14369187,  0.30882006,\n",
       "          0.39295791,  0.30843104,  0.19334039,  0.39489932,  0.30928167,\n",
       "          0.3088201 ,  0.3088201 ,  0.3088201 ,  0.35294493,  0.3820222 ,\n",
       "          0.1741887 ,  0.3974225 ,  0.30843104,  0.3088201 ,  0.30843104,\n",
       "          0.3088201 ,  0.3088201 ,  0.25742682,  0.0974047 ,  0.40412963,\n",
       "          0.20145599,  0.3088201 ,  0.3088201 ,  0.30847792,  0.39874823,\n",
       "          0.17862931,  0.3088201 ,  0.41006099,  0.05084679,  0.38861647,\n",
       "          0.29715508,  0.3088201 ,  0.3088201 ,  0.30882008,  0.30882006]),\n",
       "  'split9_test_score': array([ 0.07202684,  0.06051471,  0.30081498,  0.07202684,  0.30081498,\n",
       "          0.30081498, -0.2343425 ,  0.30081491,  0.30081491,  0.00157025,\n",
       "          0.05869284,  0.30081505,  0.29964426,  0.30081433,  0.31907703,\n",
       "          0.30081504,  0.30079001,  0.19378836,  0.30081505,  0.30079746,\n",
       "          0.40711475,  0.0968196 ,  0.34602146,  0.16451273,  0.10558542,\n",
       "          0.43294758,  0.35805883,  0.30081498,  0.30079001,  0.33346271,\n",
       "          0.28515308,  0.30079746,  0.40970651,  0.10211015,  0.30081505,\n",
       "          0.3821093 ,  0.13086426,  0.38098432,  0.40075177,  0.29589275,\n",
       "          0.40648717,  0.41685432,  0.37222323,  0.40712743,  0.36629005,\n",
       "          0.32003118,  0.40762345,  0.30081504,  0.30081491,  0.2995179 ,\n",
       "          0.30081498,  0.30081505,  0.30081504,  0.30081504,  0.40761855,\n",
       "          0.30081498,  0.30081505,  0.12736142,  0.40256896,  0.29964426,\n",
       "          0.4436375 ,  0.0061182 ,  0.42977852, -0.15518489,  0.30081491,\n",
       "          0.39627771,  0.2995179 ,  0.22009637,  0.40337064,  0.30879293,\n",
       "          0.30081505,  0.30081505,  0.30081504,  0.35373386,  0.39665875,\n",
       "          0.15028489,  0.40634969,  0.2995179 ,  0.30081504,  0.2995179 ,\n",
       "          0.30081504,  0.30081504,  0.31581514,  0.13971074,  0.41454481,\n",
       "          0.22818852,  0.30081505,  0.30081504,  0.29964426,  0.4088565 ,\n",
       "          0.20097406,  0.30081504,  0.41821893,  0.03753619,  0.4212564 ,\n",
       "          0.30425453,  0.30081505,  0.30081505,  0.30081498,  0.30081491]),\n",
       "  'mean_test_score': array([ 0.12832315,  0.08201455,  0.31256123,  0.12832315,  0.31256123,\n",
       "          0.31256123, -0.17996022,  0.31256123,  0.31256123,  0.04376319,\n",
       "          0.05995277,  0.31256123,  0.31249036,  0.31256124,  0.33497579,\n",
       "          0.31256123,  0.31256193,  0.18134743,  0.31256123,  0.31256176,\n",
       "          0.41795157,  0.06010519,  0.35356744,  0.1852307 ,  0.15820918,\n",
       "          0.44047256,  0.37046145,  0.31256123,  0.31256193,  0.34960036,\n",
       "          0.28190058,  0.31256176,  0.41523915,  0.14742683,  0.31256123,\n",
       "          0.39015931,  0.18327137,  0.38798552,  0.40778552,  0.32815514,\n",
       "          0.41176552,  0.42111083,  0.37674959,  0.41305352,  0.36722356,\n",
       "          0.31533918,  0.41429431,  0.31256123,  0.31256123,  0.31247369,\n",
       "          0.31256123,  0.31256123,  0.31256123,  0.31256123,  0.41431088,\n",
       "          0.31256123,  0.31256123,  0.07337037,  0.41565066,  0.31249036,\n",
       "          0.44771133,  0.06749312,  0.4449181 , -0.1561725 ,  0.31256123,\n",
       "          0.41341102,  0.31247369,  0.18816701,  0.41276707,  0.33495066,\n",
       "          0.31256123,  0.31256123,  0.31256123,  0.37388891,  0.40580357,\n",
       "          0.19796639,  0.41174427,  0.31247369,  0.31256123,  0.31247369,\n",
       "          0.31256123,  0.31256123,  0.2749793 ,  0.13129091,  0.42195926,\n",
       "          0.20119784,  0.31256123,  0.31256123,  0.31249036,  0.41300375,\n",
       "          0.18531363,  0.31256123,  0.42494668,  0.04782488,  0.42193918,\n",
       "          0.28703189,  0.31256123,  0.31256123,  0.31256123,  0.31256123]),\n",
       "  'std_test_score': array([0.02648891, 0.05318778, 0.0149683 , 0.02648891, 0.0149683 ,\n",
       "         0.0149683 , 0.04966687, 0.0149683 , 0.0149683 , 0.04816454,\n",
       "         0.03798392, 0.0149683 , 0.01479057, 0.01496823, 0.03126448,\n",
       "         0.01496831, 0.01496078, 0.02942699, 0.0149683 , 0.0149629 ,\n",
       "         0.01339613, 0.03977153, 0.02364794, 0.03015113, 0.02615792,\n",
       "         0.01483281, 0.02184588, 0.0149683 , 0.01496078, 0.02619719,\n",
       "         0.02332256, 0.0149629 , 0.01892398, 0.0259065 , 0.0149683 ,\n",
       "         0.0207828 , 0.02627008, 0.02028911, 0.01722928, 0.02886904,\n",
       "         0.01265895, 0.01305076, 0.02227262, 0.01246202, 0.02186206,\n",
       "         0.02605127, 0.01192951, 0.01496831, 0.0149683 , 0.01477613,\n",
       "         0.0149683 , 0.0149683 , 0.01496831, 0.01496831, 0.01191037,\n",
       "         0.0149683 , 0.0149683 , 0.03847873, 0.01458066, 0.01479057,\n",
       "         0.01632087, 0.0462856 , 0.01845297, 0.05510826, 0.0149683 ,\n",
       "         0.01962924, 0.01477613, 0.03098377, 0.01455201, 0.02739833,\n",
       "         0.0149683 , 0.0149683 , 0.01496831, 0.02094401, 0.01764868,\n",
       "         0.026611  , 0.01273371, 0.01477613, 0.01496831, 0.01477613,\n",
       "         0.01496831, 0.01496831, 0.02435723, 0.03732627, 0.01291096,\n",
       "         0.04079219, 0.0149683 , 0.01496831, 0.01479057, 0.01223404,\n",
       "         0.03122757, 0.01496831, 0.01485997, 0.05830527, 0.02532294,\n",
       "         0.02147535, 0.0149683 , 0.0149683 , 0.0149683 , 0.0149683 ]),\n",
       "  'rank_test_score': array([ 90,  92,  43,  90,  43,  43, 100,  38,  38,  98,  96,  60,  70,\n",
       "          37,  29,  50,  33,  86,  60,  35,   8,  95,  27,  84,  87,   3,\n",
       "          25,  43,  33,  28,  78,  35,  10,  88,  60,  21,  85,  22,  19,\n",
       "          31,  17,   7,  23,  14,  26,  32,  12,  50,  38,  73,  43,  60,\n",
       "          50,  50,  11,  43,  60,  93,   9,  70,   1,  94,   2,  99,  38,\n",
       "          13,  73,  82,  16,  30,  60,  60,  50,  24,  20,  81,  18,  73,\n",
       "          50,  73,  50,  50,  79,  89,   5,  80,  60,  50,  70,  15,  83,\n",
       "          50,   4,  97,   6,  77,  60,  60,  43,  38])},\n",
       " 'n_splits_': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Tunes hyperparameters for xgbosot\n",
    "\"\"\"\n",
    "hyperparameters = { \n",
    "    'n_estimators': [100, 500, 1000, 5000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 0.7],\n",
    "    'max_depth': [3, 6, 8],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'subsample': [0.5, 0.7, 1],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'gamma': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(xgboost.XGBRegressor(objective='reg:squarederror'), \n",
    "                         hyperparameters, scoring=make_scorer(mean_absolute_error),\n",
    "                         random_state=1, n_iter=100, cv=10, verbose=1, n_jobs=-1)\n",
    "clf.fit(train_X_scaled, train_y)\n",
    "clf.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1.0, gamma=0.5, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=0.01, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n",
      "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
      "             reg_lambda=1, scale_pos_weight=1, subsample=0.7, tree_method=None,\n",
      "             validate_parameters=False, verbosity=None)\n",
      "best score:  0.4477113293611311\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print('best score: ', clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  6.4min\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Tunes hyperparameters for RandomForest\n",
    "\"\"\"\n",
    "hyperparameters = { \n",
    "    'n_estimators': [100, 500, 1000, 5000],\n",
    "    'criterion' : ['mse', 'mae'],\n",
    "    'max_depth': [3, 6, 8, 20, None],\n",
    "    'min_samples_split' : [2, 4, 8, 16],\n",
    "    'min_samples_leaf' : [1, 2, 4],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "randomforest = RandomForestRegressor()\n",
    "\n",
    "clfRF = RandomizedSearchCV(randomforest, \n",
    "                         hyperparameters, \n",
    "                         random_state=1, n_iter=100, cv=10, verbose=2, n_jobs=-1)\n",
    "clfRF.fit(train_X_na_scaled, np.ravel(train_y_scaled))\n",
    "clfRF.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomforest = RandomForestRegressor()\n",
    "randomforest.fit(train_X_na_scaled, np.ravel(train_y_scaled))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_gpu",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
