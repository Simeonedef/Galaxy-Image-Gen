{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import ast\n",
    "import pickle\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "import swifter\n",
    "\n",
    "from analysis.generate_cluster_information_file import load, extract_all_information_query, to_df_query\n",
    "from baseline.image_processing import pixel_intensity_histogram\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "import xgboost\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('train_X.csv')\n",
    "train_y = pd.read_csv('train_y.csv')\n",
    "\n",
    "pd.to_numeric(train_X['cluster_num'])\n",
    "pd.to_numeric(train_X['cluster_num_intensities_avg'])\n",
    "pd.to_numeric(train_X['cluster_peak_intensities_avg'])\n",
    "pd.to_numeric(train_X['cluster_x_avg'])\n",
    "pd.to_numeric(train_X['cluster_y_avg'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "train_y_scaled = scaler.fit_transform(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_na = train_X.fillna(0)\n",
    "train_X_na_scaled = scaler.fit_transform(train_X_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.5432868851516257, Std Dev: 0.009487533968032862\n"
     ]
    }
   ],
   "source": [
    "model = xgboost.XGBRegressor(objective=\"reg:squarederror\", learning_rate =0.01, booster='gbtree', n_estimators=1000, max_depth=6, gamma=0.5, subsample=0.7, colsample_bytree=1.0, nthread=-1, verbosity=1)\n",
    "score_mi = cross_val_score(model, train_X_scaled, np.ravel(train_y_scaled), cv=5, scoring=make_scorer(mean_absolute_error))\n",
    "print(\"Mean: {}, Std Dev: {}\".format(score_mi.mean(), np.std(score_mi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.6320241650837227, Std Dev: 0.011360807620951735\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "score_mi = cross_val_score(clf, train_X_na_scaled, np.ravel(train_y_scaled), cv=5, scoring=make_scorer(mean_absolute_error))\n",
    "print(\"Mean: {}, Std Dev: {}\".format(score_mi.mean(), np.std(score_mi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RBF Kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.559523543350321, Std Dev: 0.013994445700721255\n"
     ]
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "\n",
    "score_mi = cross_val_score(svr_rbf, train_X_na_scaled, np.ravel(train_y_scaled), cv=5, scoring=make_scorer(mean_absolute_error))\n",
    "print(\"Mean: {}, Std Dev: {}\".format(score_mi.mean(), np.std(score_mi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Mean: 0.6020756297432326, Std Dev: 0.0145266920724527\n"
     ]
    }
   ],
   "source": [
    "svr_lin = SVR(kernel='linear', C=100, gamma='auto', verbose=True)\n",
    "\n",
    "score_mi = cross_val_score(svr_lin, train_X_na_scaled, np.ravel(train_y_scaled), cv=5, scoring=make_scorer(mean_absolute_error))\n",
    "print(\"Mean: {}, Std Dev: {}\".format(score_mi.mean(), np.std(score_mi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial Kernal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.5757662231202911, Std Dev: 0.011833120124295313\n"
     ]
    }
   ],
   "source": [
    "svr_poly = SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,\n",
    "               coef0=1)\n",
    "\n",
    "score_mi = cross_val_score(svr_poly, train_X_na_scaled, np.ravel(train_y_scaled), cv=5, scoring=make_scorer(mean_absolute_error))\n",
    "print(\"Mean: {}, Std Dev: {}\".format(score_mi.mean(), np.std(score_mi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.9495764713124867, Std Dev: 0.015721076633129598\n"
     ]
    }
   ],
   "source": [
    "isoforest = IsolationForest(random_state=0)\n",
    "\n",
    "score_mi = cross_val_score(isoforest, train_X_na_scaled, np.ravel(train_y_scaled), cv=5, scoring=make_scorer(mean_absolute_error))\n",
    "print(\"Mean: {}, Std Dev: {}\".format(score_mi.mean(), np.std(score_mi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.5470079355789131, Std Dev: 0.007756689915654611\n"
     ]
    }
   ],
   "source": [
    "randomforest = RandomForestRegressor(max_depth=6, random_state=0)\n",
    "\n",
    "score_mi = cross_val_score(randomforest, train_X_na_scaled, np.ravel(train_y_scaled), cv=5, scoring=make_scorer(mean_absolute_error))\n",
    "print(\"Mean: {}, Std Dev: {}\".format(score_mi.mean(), np.std(score_mi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(test_df):\n",
    "    cluster_sizes_avg = np.empty(len(test_df.index))\n",
    "    cluster_peak_intensities_avg = np.empty(len(test_df.index))\n",
    "    cluster_num_intensities_avg = np.empty(len(test_df.index))\n",
    "\n",
    "    cluster_x_avg = np.empty(len(test_df.index))\n",
    "    cluster_y_avg = np.empty(len(test_df.index))\n",
    "\n",
    "    for i in tqdm(range(len(test_df.index))):\n",
    "        c_s = test_df.iloc[i,2]\n",
    "        c_p_i = test_df.iloc[i,3]\n",
    "        c_n_i = test_df.iloc[i,4]\n",
    "        cluster_sizes_avg[i] = np.average(np.array(c_s))\n",
    "        cluster_peak_intensities_avg[i] = np.average(np.array(c_p_i))\n",
    "        cluster_num_intensities_avg[i] = np.average(np.array(c_n_i))\n",
    "        cluster_num = test_df.iloc[i,1]\n",
    "        cluster_centers = test_df.iloc[i,5]\n",
    "        temp_x = np.empty(cluster_num)\n",
    "        temp_y = np.empty(cluster_num)\n",
    "        for j in range(cluster_num):\n",
    "            (x,y) = cluster_centers[j]\n",
    "            temp_x[j] = x \n",
    "            temp_y[j] = y\n",
    "        cluster_x_avg[i] = np.average(temp_x)\n",
    "        cluster_y_avg[i] = np.average(temp_y)\n",
    "\n",
    "    # [cluster_num, cluster_num_intensities_avg, cluster_peak_intensities_avg, cluster_x_avg, cluster_y_avg]\n",
    "    eval_X = np.empty((len(test_df.index),5))\n",
    "\n",
    "    for i in tqdm(range(len(test_df.index))):\n",
    "        eval_X[i,0] = test_df.iloc[i,1]\n",
    "        eval_X[i, 1] = cluster_num_intensities_avg[i]\n",
    "        eval_X[i, 2] = cluster_peak_intensities_avg[i]\n",
    "        eval_X[i, 3] = cluster_x_avg[i]\n",
    "        eval_X[i, 4] = cluster_y_avg[i]\n",
    "        \n",
    "    return eval_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=1200.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=1200.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=1200.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=1200.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_df.csv')\n",
    "# pd saves lists as strings, so we need to convert them to lists manually\n",
    "test_df.cluster_sizes = test_df.cluster_sizes.swifter.apply(ast.literal_eval)\n",
    "test_df.cluster_centers = test_df.cluster_centers.swifter.apply(ast.literal_eval)\n",
    "test_df.cluster_peak_intensities = test_df.cluster_peak_intensities.swifter.apply(ast.literal_eval)\n",
    "test_df.cluster_num_intensities = test_df.cluster_num_intensities.swifter.apply(ast.literal_eval)\n",
    "\n",
    "assert type(test_df.cluster_sizes.tolist()[0]) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>background_threshold</th>\n",
       "      <th>cluster_num</th>\n",
       "      <th>cluster_sizes</th>\n",
       "      <th>cluster_peak_intensities</th>\n",
       "      <th>cluster_num_intensities</th>\n",
       "      <th>cluster_centers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>[6, 20, 109, 1, 8, 2, 4, 3, 57, 8, 32, 4, 5, 2...</td>\n",
       "      <td>[1, 3, 111, 1, 1, 1, 1, 1, 22, 1, 4, 1, 1, 1, ...</td>\n",
       "      <td>[1, 3, 36, 1, 1, 1, 1, 1, 17, 1, 4, 1, 1, 1, 2...</td>\n",
       "      <td>[(1, 39), (5, 295), (30, 107), (25, 286), (46,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187</td>\n",
       "      <td>20943</td>\n",
       "      <td>[69, 1, 70, 4, 381, 111, 73, 70, 1, 16, 41, 26...</td>\n",
       "      <td>[254, 191, 254, 242, 254, 251, 251, 250, 219, ...</td>\n",
       "      <td>[33, 1, 36, 4, 62, 41, 37, 34, 1, 14, 22, 18, ...</td>\n",
       "      <td>[(1, 10), (0, 18), (2, 25), (1, 41), (17, 56),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>[4, 82, 11, 7, 2, 40, 102, 160, 3, 6, 7, 54, 3...</td>\n",
       "      <td>[1, 4, 2, 5, 1, 5, 85, 251, 1, 2, 1, 29, 1, 1,...</td>\n",
       "      <td>[1, 4, 2, 4, 1, 5, 34, 54, 1, 2, 1, 17, 1, 1, ...</td>\n",
       "      <td>[(0, 906), (19, 900), (61, 728), (130, 428), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>[197, 9, 19, 59, 5, 10, 45, 18, 35, 84, 19, 20...</td>\n",
       "      <td>[26, 4, 7, 7, 4, 4, 19, 4, 13, 9, 6, 46, 49, 4...</td>\n",
       "      <td>[19, 1, 4, 4, 1, 1, 12, 1, 9, 6, 3, 30, 23, 1,...</td>\n",
       "      <td>[(17, 159), (22, 965), (50, 794), (101, 387), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>[12, 16, 8, 120, 11, 14, 8, 25, 8, 5, 5, 7, 85...</td>\n",
       "      <td>[4, 3, 3, 5, 3, 3, 3, 6, 3, 3, 3, 3, 69, 255, ...</td>\n",
       "      <td>[2, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 28, 89, 1...</td>\n",
       "      <td>[(7, 567), (10, 67), (18, 448), (37, 14), (36,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   background_threshold  cluster_num  \\\n",
       "0                     0           94   \n",
       "1                   187        20943   \n",
       "2                     0           64   \n",
       "3                     3           50   \n",
       "4                     2           57   \n",
       "\n",
       "                                       cluster_sizes  \\\n",
       "0  [6, 20, 109, 1, 8, 2, 4, 3, 57, 8, 32, 4, 5, 2...   \n",
       "1  [69, 1, 70, 4, 381, 111, 73, 70, 1, 16, 41, 26...   \n",
       "2  [4, 82, 11, 7, 2, 40, 102, 160, 3, 6, 7, 54, 3...   \n",
       "3  [197, 9, 19, 59, 5, 10, 45, 18, 35, 84, 19, 20...   \n",
       "4  [12, 16, 8, 120, 11, 14, 8, 25, 8, 5, 5, 7, 85...   \n",
       "\n",
       "                            cluster_peak_intensities  \\\n",
       "0  [1, 3, 111, 1, 1, 1, 1, 1, 22, 1, 4, 1, 1, 1, ...   \n",
       "1  [254, 191, 254, 242, 254, 251, 251, 250, 219, ...   \n",
       "2  [1, 4, 2, 5, 1, 5, 85, 251, 1, 2, 1, 29, 1, 1,...   \n",
       "3  [26, 4, 7, 7, 4, 4, 19, 4, 13, 9, 6, 46, 49, 4...   \n",
       "4  [4, 3, 3, 5, 3, 3, 3, 6, 3, 3, 3, 3, 69, 255, ...   \n",
       "\n",
       "                             cluster_num_intensities  \\\n",
       "0  [1, 3, 36, 1, 1, 1, 1, 1, 17, 1, 4, 1, 1, 1, 2...   \n",
       "1  [33, 1, 36, 4, 62, 41, 37, 34, 1, 14, 22, 18, ...   \n",
       "2  [1, 4, 2, 4, 1, 5, 34, 54, 1, 2, 1, 17, 1, 1, ...   \n",
       "3  [19, 1, 4, 4, 1, 1, 12, 1, 9, 6, 3, 30, 23, 1,...   \n",
       "4  [2, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 28, 89, 1...   \n",
       "\n",
       "                                     cluster_centers  \n",
       "0  [(1, 39), (5, 295), (30, 107), (25, 286), (46,...  \n",
       "1  [(1, 10), (0, 18), (2, 25), (1, 41), (17, 56),...  \n",
       "2  [(0, 906), (19, 900), (61, 728), (130, 428), (...  \n",
       "3  [(17, 159), (22, 965), (50, 794), (101, 387), ...  \n",
       "4  [(7, 567), (10, 67), (18, 448), (37, 14), (36,...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:01<00:00, 672.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 1200/1200 [00:00<00:00, 78046.87it/s]\n"
     ]
    }
   ],
   "source": [
    "del test_df['Unnamed: 0']\n",
    "eval_X = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "eval_X_scaled = scaler.fit_transform(eval_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1.0, gamma=0.5, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.01, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=0.7, tree_method=None,\n",
       "             validate_parameters=False, verbosity=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X_scaled, train_y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(eval_X_scaled)\n",
    "predictions = scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000956</td>\n",
       "      <td>0.673292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007209</td>\n",
       "      <td>-0.027038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016681</td>\n",
       "      <td>0.602007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1043763</td>\n",
       "      <td>0.441347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1051472</td>\n",
       "      <td>0.723479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>9962129</td>\n",
       "      <td>0.736932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>9968166</td>\n",
       "      <td>-0.006876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>9972585</td>\n",
       "      <td>0.595115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>9981103</td>\n",
       "      <td>0.454601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>9997253</td>\n",
       "      <td>-0.021728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  Predicted\n",
       "0     1000956   0.673292\n",
       "1     1007209  -0.027038\n",
       "2     1016681   0.602007\n",
       "3     1043763   0.441347\n",
       "4     1051472   0.723479\n",
       "...       ...        ...\n",
       "1195  9962129   0.736932\n",
       "1196  9968166  -0.006876\n",
       "1197  9972585   0.595115\n",
       "1198  9981103   0.454601\n",
       "1199  9997253  -0.021728\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_file_ids = [x.replace('.png', '') for x in os.listdir(os.path.join('data','query'))]\n",
    "results = {'Id': predictions_file_ids, 'Predicted': predictions.reshape(-1)}\n",
    "results = pd.DataFrame(data=results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7452475</td>\n",
       "      <td>0.585724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7071865</td>\n",
       "      <td>0.746074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9302616</td>\n",
       "      <td>0.462073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7562317</td>\n",
       "      <td>0.431731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5940084</td>\n",
       "      <td>0.614026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>9022030</td>\n",
       "      <td>0.459659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2640528</td>\n",
       "      <td>1.056854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1114602</td>\n",
       "      <td>0.916864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>6934039</td>\n",
       "      <td>0.683403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>3616311</td>\n",
       "      <td>0.499878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  Predicted\n",
       "0     7452475   0.585724\n",
       "1     7071865   0.746074\n",
       "2     9302616   0.462073\n",
       "3     7562317   0.431731\n",
       "4     5940084   0.614026\n",
       "...       ...        ...\n",
       "1195  9022030   0.459659\n",
       "1196  2640528   1.056854\n",
       "1197  1114602   0.916864\n",
       "1198  6934039   0.683403\n",
       "1199  3616311   0.499878\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preparing output for the kaggle submission\n",
    "query_ex_path = os.path.join('data', 'query_example.csv')\n",
    "query_ex = pd.read_csv(query_ex_path)\n",
    "query_ex = query_ex.iloc[:,[0]]\n",
    "\n",
    "query_ex = query_ex.astype(str)\n",
    "results['Id'].astype(str)\n",
    "\n",
    "query_preds = pd.merge(query_ex, results, on=['Id'])\n",
    "pd.to_numeric(query_preds['Predicted'])\n",
    "query_preds.loc[query_preds['Predicted'] < 0.0, 'Predicted'] = 0.0\n",
    "query_preds.loc[query_preds['Predicted'] > 8.0, 'Predicted'] = 8.0\n",
    "query_preds.to_csv('out.csv', index=False)\n",
    "query_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_gpu",
   "language": "python",
   "name": "tf2_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
