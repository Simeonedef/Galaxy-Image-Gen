{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scored_hist = pd.read_csv(\"../data/scored_histograms.csv\", index_col=\"Id\")\n",
    "# query_hist = pd.read_csv(\"../data/query_histograms.csv\", index_col=\"Id\")\n",
    "# scored_pca = pd.read_csv(\"../data/scored_features.csv\", index_col=\"Id\")\n",
    "# query_pca = pd.read_csv(\"../data/query_features.csv\", index_col=\"Id\")\n",
    "scored_features = pd.read_csv(\"../data/scored_features_400_bins.csv\", index_col=\"Id\")\n",
    "# scored_features.drop(columns=['Actual', 'Unnamed: 0'], inplace=True)\n",
    "# scored_features.columns = [col + \"_f\" for col in scored_features.columns]\n",
    "query_features = pd.read_csv(\"../data/query_features_400_bins.csv\", index_col=\"Id\")\n",
    "# query_features.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# query_features.columns = [col + \"_f\" for col in query_features.columns]\n",
    "\n",
    "X = scored_features.drop(columns=['Actual'])\n",
    "# reduce this histogram to fewer buckets, should divide 256\n",
    "num_buckets = 32\n",
    "# X = X.groupby(np.tile(np.arange(num_buckets), 256//num_buckets), axis=1).sum()\n",
    "# X['pca'] = scored_hist.iloc[:, 1]\n",
    "# X = X.join(scored_features)\n",
    "y = pd.DataFrame(scored_features['Actual'])\n",
    "\n",
    "X_test = query_features.drop(columns=['Actual'])\n",
    "# X_test = X_test.groupby(np.tile(np.arange(num_buckets), 256//num_buckets), axis=1).sum()\n",
    "# X_test['pca'] = query_hist.iloc[:, 1]\n",
    "# X_test = X_test.join(query_features)\n",
    "\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:  1.8min remaining:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   5 | elapsed:  1.8min remaining:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  2.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('transformer',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('clf',\n",
       "                                        XGBRegressor(base_score=0.5,\n",
       "                                                     booster='gbtree',\n",
       "                                                     colsample_bylevel=1,\n",
       "                                                     colsample_bynode=1,\n",
       "                                                     colsample_bytree=1,\n",
       "                                                     gamma=0,\n",
       "                                                     importance_type='gain',\n",
       "                                                     learning_rate=0.1,\n",
       "                                                     max_delta_step=0,\n",
       "                                                     max_depth=3,\n",
       "                                                     min_child_weight=1,...\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'clf__colsample_bytree': [0.7],\n",
       "                         'clf__learning_rate': [0.1], 'clf__max_depth': [9],\n",
       "                         'clf__n_estimators': [300],\n",
       "                         'clf__objective': ['reg:squarederror'],\n",
       "                         'clf__reg_alpha': [2], 'clf__reg_lambda': [2]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"clf__n_estimators\": [200, 300, 400],\n",
    "    \"clf__max_depth\": [3, 6, 9],\n",
    "    \"clf__colsample_bytree\": [0.7],\n",
    "    \"clf__reg_lambda\": [2],\n",
    "    \"clf__reg_alpha\" : [2],\n",
    "    \"clf__learning_rate\": [0.1],\n",
    "    \"clf__objective\": [\"reg:squarederror\"]\n",
    "}\n",
    "\n",
    "fast_hyperparams = {\n",
    "    \"clf__n_estimators\": [300],\n",
    "    \"clf__max_depth\": [9],\n",
    "    \"clf__colsample_bytree\": [0.7],\n",
    "    \"clf__reg_lambda\": [2],\n",
    "    \"clf__reg_alpha\" : [2],\n",
    "    \"clf__learning_rate\": [0.1],\n",
    "    \"clf__objective\": [\"reg:squarederror\"]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([('transformer', StandardScaler()),\n",
    "                         ('clf', XGBRegressor(n_jobs=2))])\n",
    "\n",
    "search = GridSearchCV(pipeline, fast_hyperparams, cv=5, verbose=10, n_jobs=4, refit=True, scoring=scorer)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scoring': make_scorer(mean_absolute_error, greater_is_better=False),\n",
       " 'estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf',\n",
       "                  XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0,\n",
       "                               importance_type='gain', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=3, min_child_weight=1,\n",
       "                               missing=None, n_estimators=100, n_jobs=2,\n",
       "                               nthread=None, objective='reg:linear',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=1, seed=None, silent=None,\n",
       "                               subsample=1, verbosity=1))],\n",
       "          verbose=False),\n",
       " 'n_jobs': 4,\n",
       " 'iid': 'deprecated',\n",
       " 'refit': True,\n",
       " 'cv': 5,\n",
       " 'verbose': 10,\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'error_score': nan,\n",
       " 'return_train_score': False,\n",
       " 'param_grid': {'clf__n_estimators': [300],\n",
       "  'clf__max_depth': [9],\n",
       "  'clf__colsample_bytree': [0.7],\n",
       "  'clf__reg_lambda': [2],\n",
       "  'clf__reg_alpha': [2],\n",
       "  'clf__learning_rate': [0.1],\n",
       "  'clf__objective': ['reg:squarederror']},\n",
       " 'multimetric_': False,\n",
       " 'best_index_': 0,\n",
       " 'best_score_': -0.11261988641064931,\n",
       " 'best_params_': {'clf__colsample_bytree': 0.7,\n",
       "  'clf__learning_rate': 0.1,\n",
       "  'clf__max_depth': 9,\n",
       "  'clf__n_estimators': 300,\n",
       "  'clf__objective': 'reg:squarederror',\n",
       "  'clf__reg_alpha': 2,\n",
       "  'clf__reg_lambda': 2},\n",
       " 'best_estimator_': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('clf',\n",
       "                  XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.7, gamma=0,\n",
       "                               importance_type='gain', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=9, min_child_weight=1,\n",
       "                               missing=None, n_estimators=300, n_jobs=2,\n",
       "                               nthread=None, objective='reg:squarederror',\n",
       "                               random_state=0, reg_alpha=2, reg_lambda=2,\n",
       "                               scale_pos_weight=1, seed=None, silent=None,\n",
       "                               subsample=1, verbosity=1))],\n",
       "          verbose=False),\n",
       " 'refit_time_': 64.02286434173584,\n",
       " 'scorer_': make_scorer(mean_absolute_error, greater_is_better=False),\n",
       " 'cv_results_': {'mean_fit_time': array([94.20093479]),\n",
       "  'std_fit_time': array([23.58915945]),\n",
       "  'mean_score_time': array([0.13194714]),\n",
       "  'std_score_time': array([0.05869396]),\n",
       "  'param_clf__colsample_bytree': masked_array(data=[0.7],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_clf__learning_rate': masked_array(data=[0.1],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_clf__max_depth': masked_array(data=[9],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_clf__n_estimators': masked_array(data=[300],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_clf__objective': masked_array(data=['reg:squarederror'],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_clf__reg_alpha': masked_array(data=[2],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_clf__reg_lambda': masked_array(data=[2],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'clf__colsample_bytree': 0.7,\n",
       "    'clf__learning_rate': 0.1,\n",
       "    'clf__max_depth': 9,\n",
       "    'clf__n_estimators': 300,\n",
       "    'clf__objective': 'reg:squarederror',\n",
       "    'clf__reg_alpha': 2,\n",
       "    'clf__reg_lambda': 2}],\n",
       "  'split0_test_score': array([-0.11403675]),\n",
       "  'split1_test_score': array([-0.1142518]),\n",
       "  'split2_test_score': array([-0.10883074]),\n",
       "  'split3_test_score': array([-0.11096418]),\n",
       "  'split4_test_score': array([-0.11501596]),\n",
       "  'mean_test_score': array([-0.11261989]),\n",
       "  'std_test_score': array([0.00234567]),\n",
       "  'rank_test_score': array([1], dtype=int32)},\n",
       " 'n_splits_': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = search.predict(X_test)\n",
    "output = pd.DataFrame(columns=[\"Predicted\"])\n",
    "output[\"Id\"] = X_test.index\n",
    "output[\"Predicted\"] = test_predictions\n",
    "output.set_index(\"Id\", inplace=True)\n",
    "output.to_csv(\"res.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aml]",
   "language": "python",
   "name": "conda-env-aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
